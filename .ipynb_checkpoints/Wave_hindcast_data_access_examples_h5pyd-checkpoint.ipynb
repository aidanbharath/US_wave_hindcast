{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NREL Wave Hindacast Data Access Example\n",
    "\n",
    "#### This notebook demonstrates basic usage of the National Renewable Energy Laboratory (NREL) West Coast Wave Hindcast dataset. The data is provided from Amazon Web Services using the HDF Group's Highly Scalable Data Service (HSDS).\n",
    "\n",
    "#### For this to work you must first install h5pyd:\n",
    "\n",
    "pip install --user h5pyd\n",
    "\n",
    "#### Next you'll need to configure HSDS:\n",
    "\n",
    "hsconfigure\n",
    "\n",
    "#### and enter at the prompt:\n",
    "\n",
    "hs_endpoint = https://developer.nrel.gov/api/hsds\n",
    "\n",
    "hs_username = None\n",
    "\n",
    "hs_password = None\n",
    "\n",
    "hs_api_key = 3K3JQbjZmWctY0xmIfSYvYgtIcM3CN0cb1Y2w9bf\n",
    "\n",
    "#### The example API key here is for demonstation and is rate-limited per IP. To get your own API key, visit https://developer.nrel.gov/signup/\n",
    "\n",
    "#### You can also add the above contents to a configuration file at ~/.hscfg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5pyd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pyproj import Proj\n",
    "from scipy.spatial import cKDTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Usage\n",
    "\n",
    "The Wave Hindcast Dataset is provided in annual .h5 files and currently spans the Western Coastal Region of the Lower 48 from 1979-2010.\n",
    "\n",
    "Each year can be accessed from /nrel/us-wave/US_Wave_${year}.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the desired year of Wave Hindcast data\n",
    "# server endpoint, username, password is found via a config file\n",
    "\n",
    "waves = h5pyd.File(f'/nrel/us-wave/US_Wave_1990.h5','r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(waves.attrs) # list of base attributes of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "\n",
    "What follows are basic examples of navigating the dataset and discovering variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['coordinates',\n",
       " 'directionality_coefficient',\n",
       " 'energy_period',\n",
       " 'maximum_energy_direction',\n",
       " 'mean_absolute_period',\n",
       " 'mean_wave_direction',\n",
       " 'mean_zero-crossing_period',\n",
       " 'meta',\n",
       " 'omni-directional_wave_power',\n",
       " 'peak_period',\n",
       " 'significant_water_height',\n",
       " 'spectral_width',\n",
       " 'time_index',\n",
       " 'water_depth']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List the available dataset variable names within the dataset\n",
    "\n",
    "list(waves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locational information is stored in either 'meta' or 'coordinates'\n",
    "\n",
    "meta = pd.DataFrame(waves['meta'][:])\n",
    "meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2920, 699904)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shapes of datasets\n",
    "waves['significant_water_height'].shape # (time, lon_lat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Slicing\n",
    "\n",
    "Basic description of timestamp extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=3, read=2, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))': /api/hsds/datasets/d-4678d458-2095d296-0077-24bb4a-8a5dd4/value?select=%5B0%3A2920%3A1%5D&domain=%2Fnrel%2Fus-wave%2FUS_Wave_1990.h5&api_key=3K3JQbjZmWctY0xmIfSYvYgtIcM3CN0cb1Y2w9bf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(DatetimeIndex(['1990-01-01 00:00:00+00:00', '1990-01-01 03:00:00+00:00',\n",
       "                '1990-01-01 06:00:00+00:00', '1990-01-01 09:00:00+00:00',\n",
       "                '1990-01-01 12:00:00+00:00', '1990-01-01 15:00:00+00:00',\n",
       "                '1990-01-01 18:00:00+00:00', '1990-01-01 21:00:00+00:00',\n",
       "                '1990-01-02 00:00:00+00:00', '1990-01-02 03:00:00+00:00',\n",
       "                ...\n",
       "                '1990-12-30 18:00:00+00:00', '1990-12-30 21:00:00+00:00',\n",
       "                '1990-12-31 00:00:00+00:00', '1990-12-31 03:00:00+00:00',\n",
       "                '1990-12-31 06:00:00+00:00', '1990-12-31 09:00:00+00:00',\n",
       "                '1990-12-31 12:00:00+00:00', '1990-12-31 15:00:00+00:00',\n",
       "                '1990-12-31 18:00:00+00:00', '1990-12-31 21:00:00+00:00'],\n",
       "               dtype='datetime64[ns, UTC]', length=2920, freq=None),\n",
       " '3H')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract datetime index for datasets (Saved as binary)\n",
    "\n",
    "time_index = pd.to_datetime(waves['time_index'][:].astype(str))\n",
    "time_index, time_index.inferred_freq # Temporal resolution is 3 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "Aug_7th_midnight = time_index.get_loc('1990-08-07 00:00:00') #precise data returns single index\n",
    "Aug = time_index.get_loc('1990-08') #Inprecise will return a range a values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "August 7th midnight: 1990-08-07 00:00:00+00:00\n",
      "Month of August: DatetimeIndex(['1990-08-01 00:00:00+00:00', '1990-08-01 03:00:00+00:00',\n",
      "               '1990-08-01 06:00:00+00:00', '1990-08-01 09:00:00+00:00',\n",
      "               '1990-08-01 12:00:00+00:00', '1990-08-01 15:00:00+00:00',\n",
      "               '1990-08-01 18:00:00+00:00', '1990-08-01 21:00:00+00:00',\n",
      "               '1990-08-02 00:00:00+00:00', '1990-08-02 03:00:00+00:00',\n",
      "               ...\n",
      "               '1990-08-30 18:00:00+00:00', '1990-08-30 21:00:00+00:00',\n",
      "               '1990-08-31 00:00:00+00:00', '1990-08-31 03:00:00+00:00',\n",
      "               '1990-08-31 06:00:00+00:00', '1990-08-31 09:00:00+00:00',\n",
      "               '1990-08-31 12:00:00+00:00', '1990-08-31 15:00:00+00:00',\n",
      "               '1990-08-31 18:00:00+00:00', '1990-08-31 21:00:00+00:00'],\n",
      "              dtype='datetime64[ns, UTC]', length=248, freq=None)\n"
     ]
    }
   ],
   "source": [
    "print(f'August 7th midnight: {time_index[Aug_7th_midnight]}')\n",
    "print(f'Month of August: {time_index[Aug]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping Data\n",
    "\n",
    "Basic methods to quickly plot data from the Hindcast spatially and temporally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatial Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=3, read=2, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))': /api/hsds/datasets/d-4678d458-2095d296-de7f-e5b90f-148981/value?select=%5B0%3A699904%3A100%2C0%3A2%3A1%5D&domain=%2Fnrel%2Fus-wave%2FUS_Wave_1990.h5&api_key=3K3JQbjZmWctY0xmIfSYvYgtIcM3CN0cb1Y2w9bf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available attributes: {'description': '(latitude, longitude) using Datum: NAD83', 'dimensions': array([array('position', dtype='<U8')], dtype=object), 'src_name': '(Xp, Yp)', 'units': '(deg, deg)'}\n",
      "Coordinate pairs: [[  48.8641 -125.386 ]\n",
      " [  46.1511 -129.577 ]\n",
      " [  41.74   -129.538 ]\n",
      " ...\n",
      " [  37.4535 -122.072 ]\n",
      " [  37.4517 -122.055 ]\n",
      " [  37.4617 -122.027 ]]\n"
     ]
    }
   ],
   "source": [
    "# the view the available coordinates which are provided as lat,lon pairs\n",
    "\n",
    "coord_slice = 100\n",
    "\n",
    "print(f'Available attributes: {dict(waves[\"coordinates\"].attrs)}')\n",
    "coords = waves['coordinates'][::coord_slice]\n",
    "print(f'Coordinate pairs: {coords}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7000,)\n",
      "(70,)\n"
     ]
    }
   ],
   "source": [
    "# Building a scatter plot of significant wave height values\n",
    "\n",
    "df = pd.DataFrame() # Combine data with coordinates in a DataFrame\n",
    "df['longitude'] = coords[:, 1]\n",
    "df['latitude'] = coords[:, 0]\n",
    "df['Hsig'] = waves['significant_water_height'][Aug_7th_midnight, ::coord_slice] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "465023df64f7468e9613c85bc1add29b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "df['Hsig'][df['Hsig']<0] = np.nan # There are negative values here Levi\n",
    "df.plot.scatter(x='longitude', y='latitude', c='Hsig',\n",
    "                colormap='viridis',\n",
    "                title=str(time_index[Aug_7th_midnight]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Site index: 2567\n",
      "Coordinates Searched: (39.6122, -125.318)\n",
      "Coordinates of Nearest Point: [  39.546 -125.174]\n"
     ]
    }
   ],
   "source": [
    "# Extracting a timeseries usually requires us to find a location of interest.\n",
    "# This can be done easially with KDTree\n",
    "\n",
    "tree = cKDTree(coords)\n",
    "def nearest_site(tree, lat_coord, lon_coord):\n",
    "    lat_lon = np.array([lat_coord, lon_coord])\n",
    "    dist, pos = tree.query(lat_lon)\n",
    "    return pos\n",
    "\n",
    "lat_coord, lon_coord = 39.6122, -125.318\n",
    "site_idx = nearest_site(tree, lat_coord, lon_coord)\n",
    "\n",
    "print(f'Site index: {site_idx}')\n",
    "print(f'Coordinates Searched: {lat_coord, lon_coord}')\n",
    "print(f'Coordinates of Nearest Point: {coords[site_idx]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68e68b41283c4bb18b4085034f0573a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f5410ca7160>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we can extract data at that location over a specified time range\n",
    "\n",
    "var = 'peak_period'\n",
    "\n",
    "dt = pd.DataFrame(waves[var][Aug,site_idx],index=time_index[Aug],columns=[var])\n",
    "dt.plot(y=var,title=f'Time sliced {var} Timeseries')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Statistics and Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is an example of grouping data to create quick plots of stats\n",
    "\n",
    "Vars =['significant_water_height','peak_period'] \n",
    "variables = np.array([waves[Vars[0]][Aug,site_idx], waves[Vars[1]][Aug,site_idx]])\n",
    "\n",
    "ds = pd.DataFrame(variables.T,\n",
    "                    index=time_index[Aug],\n",
    "                    columns=Vars\n",
    "                )\n",
    "group = ds.groupby('peak_period')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bd5db1dbe9141bd896329bef24e6a2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f5402bd8a58>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot the number of occurances of sea-states within peak period bins\n",
    "\n",
    "group.count().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "226aa64979814b86b02bea3b3f0c5488",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f5402a6ce48>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plot the mean Hsig of the sea-states within peak period bins along with\n",
    "# the variance of those waveheights\n",
    "\n",
    "group.mean().plot(kind='bar',yerr=group.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
